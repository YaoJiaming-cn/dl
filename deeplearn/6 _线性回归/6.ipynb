{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a110aa7-5abc-4a6e-b23c-826e41066b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 False\n"
     ]
    }
   ],
   "source": [
    "# 均方误差、小批量随机梯度下降\n",
    "\n",
    "import torch\n",
    "from time import time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "#测试两种加法耗时\n",
    "a = torch.randn(1000, device = device)\n",
    "b = torch.randn(1000, device = device)\n",
    "print(a.device, a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0022888c-3b13-4d24-8126-4465765cd73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0651559829711914 cpu\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "c = torch.zeros(1000)\n",
    "for i in range(1000):\n",
    "    c[i] = a[i] + b[i]\n",
    "print(time() - start, c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd0cfc1-b446-4a8b-a4c3-4c4de29021aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 cuda:0\n"
     ]
    }
   ],
   "source": [
    "#更快\n",
    "start = time()\n",
    "c = a + b\n",
    "print(time() - start, c.device)\n",
    "#直接定义的c是在cpu上，由gpu上的tensor运算得到的c是在gpu上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19db471a-0364-46e8-8c0f-d2a124bfffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bacf983-10bd-4c17-b131-a5c3e897a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2 #特征数\n",
    "num_examples = 1000 #样本数\n",
    "\n",
    "#在实际问题上true_w喝true_b不知道，只不过这里是在模拟数据，是用来计算真实的y的\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "\"\"\"\n",
    "#np.random.normal(loc, scale, size)中loc是期望，scale是标准差，size是大小\n",
    "features = torch.from_numpy(np.random.normal(0, 1, (num_examples, num_inputs)))\n",
    "#要dtype = float，features和int的w不能乘\n",
    "labels = features @ torch.tensor(true_w, dtype = float).t() + true_b\n",
    "labels += torch.from_numpy(np.random.normal(0, 0.01, labels.size()))\n",
    "#print(labels)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "以上代码会导致kernel内核挂掉，疑似为以下原因\n",
    "1.float类型冲突，所以全指定torch.float32\n",
    "2..t()转置使用错误，true_w = [2, -3.4]是一个一维向量，size为[2]，而.t() 只对二维张量转置\n",
    "    所以可以直接不用转置，因为pytorch的特性，让 1D 张量既可以当行向量，也可以当列向量用\n",
    "3.torch.from_numpy() 和 np.random.normal() 生成的数组是共享内存的，可能导致崩溃，所以用torch.tensor()不共享内存\n",
    "\"\"\"\n",
    "features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype = torch.float32)\n",
    "labels = features @ torch.tensor(true_w, dtype = torch.float32)+ true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size = labels.size()), dtype = torch.float32)\n",
    "\n",
    "\n",
    "#好吧还是崩溃了。。重开一个book吧\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (20, 8), dpi = 80)\n",
    "plt.scatter(features[:, 0].numpy(),labels.numpy())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_env)",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
